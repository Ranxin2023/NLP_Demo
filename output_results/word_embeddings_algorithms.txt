BERT demo......
The shape of embeddings are: torch.Size([1, 7, 768])
word embeddings are:
tensor([[[-0.2810, -0.0482, -0.1013,  ..., -0.4972,  0.1912,  0.9041],
         [-0.7726, -0.5249, -0.0580,  ..., -0.6560,  0.6868,  0.3801],
         [-0.3695, -0.5830,  0.4278,  ..., -0.4327,  0.0379,  0.9097],
         ...,
         [-0.1463, -0.3780,  0.0361,  ..., -0.4566, -0.2561, -0.1740],
         [-0.2732, -0.2735, -0.4977,  ...,  0.2958, -0.0060, -0.1572],
         [ 0.6660, -0.1010, -0.4946,  ...,  0.4617, -0.8314, -0.1667]]],
       grad_fn=<NativeLayerNormBackward0>)
