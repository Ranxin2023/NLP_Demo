BERT demo......
The shape of embeddings are: torch.Size([1, 7, 768])
word embeddings are:
tensor([[[-0.2810, -0.0482, -0.1013,  ..., -0.4972,  0.1912,  0.9041],
         [-0.7726, -0.5249, -0.0580,  ..., -0.6560,  0.6868,  0.3801],
         [-0.3695, -0.5830,  0.4278,  ..., -0.4327,  0.0379,  0.9097],
         ...,
         [-0.1463, -0.3780,  0.0361,  ..., -0.4566, -0.2561, -0.1740],
         [-0.2732, -0.2735, -0.4977,  ...,  0.2958, -0.0060, -0.1572],
         [ 0.6660, -0.1010, -0.4946,  ...,  0.4617, -0.8314, -0.1667]]],
       grad_fn=<NativeLayerNormBackward0>)
The shape of position embeddings are: torch.Size([1, 7, 768])
Position embeddings:
tensor([[[ 1.7505e-02, -2.5631e-02, -3.6642e-02,  ...,  3.3437e-05,
           6.8312e-04,  1.5441e-02],
         [ 7.7580e-03,  2.2613e-03, -1.9444e-02,  ...,  2.8910e-02,
           2.9753e-02, -5.3247e-03],
         [-1.1287e-02, -1.9644e-03, -1.1573e-02,  ...,  1.4908e-02,
           1.8741e-02, -7.3140e-03],
         ...,
         [-5.6087e-03, -1.0445e-02, -7.2288e-03,  ...,  2.0837e-02,
           3.5402e-03,  4.7708e-03],
         [-3.0871e-03, -1.8956e-02, -1.8930e-02,  ...,  7.4045e-03,
           2.0183e-02,  3.4077e-03],
         [ 6.4257e-03, -1.7664e-02, -2.2067e-02,  ...,  6.7531e-04,
           1.1108e-02,  3.7521e-03]]], grad_fn=<EmbeddingBackward0>)
glove demo.......
Vector for 'sample':
[-0.31059    0.66222    0.21789   -0.046964  -0.37409    0.71737
  0.92633    0.80566   -0.31682    0.54172   -0.30107   -0.1522
 -0.047403  -0.14923    0.57646    0.76697    0.21433    0.20375
  0.57335   -0.0186    -0.38483   -0.34623    0.10475   -0.48937
 -0.68399   -0.26709    0.70421    0.0032026  0.25875   -0.20735
  0.29176   -0.35039    0.078128   0.69664    0.84063    0.019594
  0.32728    0.49883   -0.4859    -0.59618   -0.13152   -0.58993
 -0.49327   -0.16369   -0.31943    0.13787   -0.75657   -0.98744
 -0.11669   -0.3329     1.1011     0.40166    0.23021    0.10653
 -0.47182   -1.2705    -0.72376   -0.10318    1.4433     0.011268
  0.29639    0.45875    0.56541    0.55125    1.2032     0.4963
  0.30035   -0.21314    0.36452   -0.07512   -0.18296    0.97547
  0.65208    0.49546    0.18021    0.70638   -0.02527   -0.88635
 -0.31636   -0.34983    0.10328    0.28178   -0.72644   -0.57728
 -1.1255    -0.30205    1.209     -0.23275   -0.34631    0.42445
 -0.48058    0.50546   -0.21942   -0.19309    0.29072    0.26906
 -0.50211   -0.33296   -0.40494    0.29489  ]

Most similar to 'sample':
[('samples', 0.8527889847755432), ('sampling', 0.7500016689300537), ('urine', 0.7264154553413391), ('measurements', 0.6070224642753601), ('analyzed', 0.5985800623893738), ('testing', 0.5975296497344971), ('dna', 0.5960320830345154), ('analysis', 0.5932361483573914), ('tests', 0.58931565284729), ('sampled', 0.5860516428947449)]
word2vec demo......

Embedding for 'nlp':
[-0.00054258 -0.0176631  -0.01723512  0.00560042 -0.01641281 -0.01813867
 -0.00468093 -0.01726362 -0.0141133  -0.0168023  -0.00060266 -0.0091286
  0.01325435  0.00305432 -0.00668295  0.01221794 -0.01202657 -0.00931234
 -0.01441502 -0.00867316 -0.00361866  0.01297929 -0.00554079  0.00983793
  0.01380888 -0.01492741  0.0091297   0.01225396 -0.00590895  0.01325004
  0.01225176 -0.01288697 -0.0135291   0.00507792 -0.00324764 -0.01213026
  0.01899842 -0.01026029 -0.01310819 -0.00023977 -0.00540286  0.0008888
 -0.00707492 -0.00083866 -0.00141723  0.00164564  0.01638963 -0.01147341
 -0.00331906  0.01114322]

Embedding for 'fun':
[ 1.62645429e-02 -8.91466811e-03 -2.13671452e-03  2.01272964e-03
 -3.82227910e-04  2.29635485e-03  1.22277215e-02 -4.05430801e-05
 -6.49193069e-03 -3.02145723e-03  1.17945978e-02  3.02820443e-03
 -1.44852395e-03  1.86664946e-02 -9.84256715e-03 -1.67681929e-03
  1.83508229e-02  1.34988548e-02  3.00571206e-03 -1.77651215e-02
  2.29749200e-03 -4.57651122e-03  1.87364742e-02  2.41985568e-03
  2.98012723e-03  4.81281988e-03 -3.67201329e-03 -9.99926776e-03
  4.64859011e-04 -4.02836083e-03  1.32018663e-02  1.78802460e-02
 -1.34950876e-03  5.95402950e-03 -1.22153088e-02  3.39864963e-03
 -1.38524650e-02 -1.73880532e-02 -1.18004056e-02 -1.79129504e-02
  1.45551898e-02 -1.15440628e-02  1.65527035e-02 -1.44870905e-02
  6.84334990e-03  1.93499979e-02 -1.55708957e-02 -1.98901147e-02
 -8.65829270e-03 -5.36626112e-03]

Embedding for 'learning':
[-1.0724545e-03  4.7286271e-04  1.0206699e-02  1.8018546e-02
 -1.8605899e-02 -1.4233618e-02  1.2917745e-02  1.7945977e-02
 -1.0030856e-02 -7.5267432e-03  1.4761009e-02 -3.0669428e-03
 -9.0732267e-03  1.3108104e-02 -9.7203208e-03 -3.6320353e-03
  5.7531595e-03  1.9837476e-03 -1.6570430e-02 -1.8897636e-02
  1.4623532e-02  1.0140524e-02  1.3515387e-02  1.5257311e-03
  1.2701781e-02 -6.8107317e-03 -1.8928028e-03  1.1537147e-02
 -1.5043275e-02 -7.8722071e-03 -1.5023164e-02 -1.8600845e-03
  1.9076237e-02 -1.4638334e-02 -4.6675373e-03 -3.8754821e-03
  1.6154874e-02 -1.1861792e-02  9.0324880e-05 -9.5074680e-03
 -1.9207101e-02  1.0014586e-02 -1.7519170e-02 -8.7836506e-03
 -7.0199967e-05 -5.9236289e-04 -1.5322480e-02  1.9229487e-02
  9.9641159e-03  1.8466286e-02]

Embedding for 'semantic':
[ 1.56351421e-02 -1.90203730e-02 -4.11062239e-04  6.93839323e-03
 -1.87794445e-03  1.67635437e-02  1.80215668e-02  1.30730132e-02
 -1.42324204e-03  1.54208085e-02 -1.70686692e-02  6.41421322e-03
 -9.27599426e-03 -1.01779103e-02  7.17923651e-03  1.07406788e-02
  1.55390287e-02 -1.15330126e-02  1.48667218e-02  1.32509926e-02
 -7.41960062e-03 -1.74912829e-02  1.08749345e-02  1.30195115e-02
 -1.57510047e-03 -1.34197120e-02 -1.41718509e-02 -4.99412045e-03
  1.02865072e-02 -7.33047491e-03 -1.87401194e-02  7.65347946e-03
  9.76895820e-03 -1.28571270e-02  2.41711619e-03 -4.14975407e-03
  4.88066689e-05 -1.97670180e-02  5.38400887e-03 -9.50021297e-03
  2.17529293e-03 -3.15244915e-03  4.39334614e-03 -1.57631524e-02
 -5.43436781e-03  5.32639725e-03  1.06933638e-02 -4.78302967e-03
 -1.90201886e-02  9.01175756e-03]

Embedding for 'machine':
[ 0.00855287  0.00015212 -0.01916856 -0.01933109 -0.01229639 -0.00025714
  0.00399483  0.01886394  0.0111687  -0.00858139  0.00055663  0.00992872
  0.01539662 -0.00228845  0.00864684 -0.01162876 -0.00160838  0.0162001
 -0.00472013 -0.01932691  0.01155852 -0.00785964 -0.00244575  0.01996103
 -0.0045127  -0.00951413 -0.01065877  0.01396178 -0.01141774  0.00422733
 -0.01051132  0.01224143  0.00871461  0.00521271 -0.00298217 -0.00549213
  0.01798587  0.01043155 -0.00432504 -0.01894062 -0.0148521  -0.00212748
 -0.00158989 -0.00512582  0.01936544 -0.00091704  0.01174752 -0.01489517
 -0.00501215 -0.01109973]

Embedding for 'embeddings':
[ 2.8740549e-03 -5.2920175e-03 -1.4147566e-02 -1.5610614e-02
 -1.8243574e-02 -1.1870339e-02 -3.6948491e-03 -8.6477427e-03
 -1.2921341e-02 -7.4346447e-03  8.5783172e-03 -7.4780867e-03
  1.6756350e-02  3.0679870e-03 -1.4484639e-02  1.8867597e-02
  1.5262425e-02  1.0986564e-02 -1.3697691e-02  1.1645358e-02
  8.0181863e-03  1.0370739e-02  8.5118031e-03  3.8795089e-03
 -6.3403249e-03  1.6707690e-02  1.9224361e-02  7.5852061e-03
 -5.6739901e-03  1.4255047e-05  2.4376370e-03 -1.6916649e-02
 -1.6447891e-02 -4.6203137e-04  2.4745751e-03 -1.1486761e-02
 -9.4505474e-03 -1.4692149e-02  1.6657231e-02  2.4259568e-04
 -9.0187974e-03  1.1403411e-02  1.8360030e-02 -8.1997439e-03
  1.5929364e-02  1.0750868e-02  1.1758246e-02  1.0251808e-03
  1.6426168e-02 -1.4038081e-02]
