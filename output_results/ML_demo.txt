Naive Bayes Demo.......

Class 0 log probabilities:
  amazing: -2.4849
  bad: -1.7918
  hate: -1.7918
  is: -1.7918
  love: -2.4849
  nlp: -2.4849
  spam: -1.3863

Class 1 log probabilities:
  amazing: -1.7918
  bad: -2.4849
  hate: -2.4849
  is: -1.7918
  love: -1.7918
  nlp: -1.3863
  spam: -2.4849
[0]
SVM demo....
ðŸ“˜ Vocabulary (word -> index):
 0: amazing
 1: bad
 2: hate
 3: is
 4: love
 5: nlp
 6: spam

ðŸ§® TF-IDF Matrix:
[[0.         0.         0.         0.         0.78528828 0.6191303
  0.        ]
 [0.66767854 0.         0.         0.52640543 0.         0.52640543
  0.        ]
 [0.         0.         0.78528828 0.         0.         0.
  0.6191303 ]
 [0.         0.66767854 0.         0.52640543 0.         0.
  0.52640543]]

ðŸ§  Support vector indices (in training set): [2 3 0 1]

ðŸ”Ž Prediction for "NLP is bad": Positive
Decision Tree Demo......
ðŸ§® Vectorized input (bag-of-words counts):
[[0 0 0 0 1 1 0]
 [1 0 0 1 0 1 0]
 [0 0 1 0 0 0 1]
 [0 1 0 1 0 0 1]] 

ðŸŒ³ Decision Tree Rules:
Tree rules are:
|--- spam <= 0.50
|   |--- class: 1
|--- spam >  0.50
|   |--- class: 0

[0]
Transfomer demo....
Input Sentense isI love using transformers for NLP
Sentiment: POSITIVE, Confidence: 0.6594
